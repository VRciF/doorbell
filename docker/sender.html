<html>
<head>
</head>
<body>
  <div class="camera">
    <video id="video">Video stream not available.</video>
  </div>

  <canvas id="canvas1" style="display:none;"></canvas>
  <canvas id="canvas2" style="display:none;"></canvas>
  <canvas id="diff" style="display:none;"></canvas>

  <div class="output">
    <img id="photo" alt="The screen capture will appear in this box.">
  </div>

  <script>

var channelName = "doorbell:resident1";
var serverSampleRate = 16000;

var recw = new Worker("recorderworker.js");
recw.onmessage = function(event) {
    switch(event.data.type){
        case 'init':
            recw.postMessage({type: "init", server: window.location.hostname, port: 8080, sampleRate: serverSampleRate, channel: channelName});
            break;
    }
};
// recw.terminate

processAudio();
//processVideo();

function processVideo(){
  var fps = 25;
  var width = 640;    // We will scale the photo width to this
  var height = 0;     // This will be computed based on the input stream

  var framecount = 0;

  var streaming = false;

  var video = null;
  var canvas = [null, null];
  var ctx = [null, null];
  var diff = document.getElementById('diff');
  var photo = null;
  var startbutton = null;

var videocnt = 0;

    video = document.getElementById('video');
    canvas[0] = document.getElementById('canvas1');
    canvas[1] = document.getElementById('canvas2');
    ctx[0] = canvas[0].getContext("2d");
    ctx[1] = canvas[1].getContext("2d");
    photo = document.getElementById('photo');

    navigator.mediaDevices.getUserMedia({ video: true, audio: false })
    .then(function(stream) {
        video.srcObject = stream;
        video.play();

        var options = {mimeType: 'video/webm; codecs=h264'};
        mediaRecorder = new MediaRecorder(stream, options);
        mediaRecorder.ondataavailable = handleDataAvailable;
        mediaRecorder.start();

        function handleDataAvailable(event) {
console.log("data available");
           if (event.data.size > 0) {
               console.log(event.data);
//               saveData(event.data, "video."+videocnt+".webm");
//               videocnt++;
           }
        }

        setInterval(function(){ mediaRecorder.stop(); mediaRecorder.start(); }, 5000);
    })
    .catch(function(err) {
        console.log("An error occured! " + err);
    });

var saveData = (function () {
    var a = document.createElement("a");
    document.body.appendChild(a);
    a.style = "display: none";
    return function (blob, fileName) {
        var url = window.URL.createObjectURL(blob);
        a.href = url;
        a.download = fileName;
        a.click();
        window.URL.revokeObjectURL(url);
    };
}());
/*
    video.addEventListener('canplay', function(ev){
      if (!streaming) {
        height = video.videoHeight / (video.videoWidth/width);
      
        video.setAttribute('width', width);
        video.setAttribute('height', height);
        canvas[0].setAttribute('width', width);
        canvas[0].setAttribute('height', height);
        canvas[1].setAttribute('width', width);
        canvas[1].setAttribute('height', height);
//        ctx[0].filter = "blur(200px)";
//        ctx[1].filter = "blur(200px)";
        diff.setAttribute('width', width);
        diff.setAttribute('height', height);
        streaming = true;
      }
    }, false);
*/
    function takePicture(){
       var i = framecount%2;
       var context = canvas[i].getContext('2d');
       if (width && height) {
           framecount++;
           canvas[i].width = width;
           canvas[i].height = height;
           context.drawImage(video, 0, 0, width, height);
    
           //var data = canvas.toDataURL('image/png');
           //photo.setAttribute('src', data);
           computeDifference();
       }
       setTimeout(takePicture, 1000/fps);
    }

    setTimeout(takePicture, 1000/fps);

    function computeDifference(){
var srcid = (framecount+1)%2;
var dstid = framecount%2;
// grab final destination canvas
var diffctx = diff.getContext('2d');
diffctx.filter = "blur(2px)";
// draw the source image on to destination
diffctx.drawImage(canvas[srcid], 0, 0);

// clock starts ticking
var start = new Date().getMilliseconds();

// calculate the difference of image 1 and image 2
diffctx.globalCompositeOperation="difference";
diffctx.drawImage(canvas[dstid], 0, 0);

// convert the pixel difference to grayscale
convertCanvasToGrayscale(diff);
// reduce pixel noise
reduceNoise(diff);
// conver the grayscale difference to black and white
convertGrayscaleCanvasToBlackNWhite(diff);
// get the exact spots of the difference in the original image 1 colors
var result = getBlendedImageWithBlackNWhite(canvas[srcid], diff);

// write the final difference into destination canvas
diffctx.globalCompositeOperation='source-over';
diffctx.drawImage(result,0,0);

dataurl = diff.toDataURL("image/webp");
console.log(dataurl.length, 0.8);

// how long did it take?
var end = new Date().getMilliseconds();
var txt = document.getElementById('txt');
//console.log("time: ", end-start);
//txt.innerHTML = "Time in Milliseconds: "+(end-start);
    }

function reduceNoise(canvas){
    var ctx = canvas.getContext('2d');
    ctx.globalCompositeOperation = 'multiply';
    ctx.drawImage(canvas, 0, 0);
}

function convertCanvasToGrayscale(canvas){
    var tmp = document.createElement('canvas');
    tmp.width = canvas.width;
    tmp.height = canvas.height;
    var tmpctx = tmp.getContext('2d');

    tmpctx.globalCompositeOperation="source-over";  // default composite value
    tmpctx.fillStyle="#FFFFFF";
    tmpctx.fillRect(0,0,canvas.width,canvas.height);
    tmpctx.globalCompositeOperation="luminosity";
    tmpctx.drawImage(canvas,0,0);

    ctx = canvas.getContext('2d');
    ctx.globalCompositeOperation="source-over";
    ctx.drawImage(tmp, 0, 0);
}

function convertGrayscaleCanvasToBlackNWhite(canvas){
    var ctx = canvas.getContext('2d');

    // in case the grayscale conversion is to bulky
    // darken the canvas bevore further black'nwhite conversion
    //for(var i=0;i<3;i++){
    //    ctx.globalCompositeOperation = 'multiply';
    //    ctx.drawImage(canvas, 0, 0);
    //}

    ctx.globalCompositeOperation = 'color-dodge';
    ctx.fillStyle = "rgba(253, 253, 253, 1)";
    ctx.beginPath();
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    ctx.fill();
    ctx.globalCompositeOperation = 'color-dodge';
    ctx.fillStyle = "rgba(253, 253, 253, 1)";
    ctx.beginPath();
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    ctx.fill();
}
function getBlendedImageWithBlackNWhite(canvasimage, canvasbw){
    var tmp = document.createElement('canvas');
    tmp.width = canvasimage.width;
    tmp.height = canvasimage.height;

    var tmpctx = tmp.getContext('2d');

    tmpctx.globalCompositeOperation = 'source-over';
    tmpctx.drawImage(canvasimage, 0, 0);

    // multiply means, that every white pixel gets replaced by canvasimage pixel
    // and every black pixel will be left black
    tmpctx.globalCompositeOperation = 'multiply';
    tmpctx.drawImage(canvasbw, 0, 0);

    return tmp;
}
function invertCanvas(canvas){
    var ctx = canvas.getContext("2d");

    ctx.globalCompositeOperation = 'difference';
    ctx.fillStyle = "rgba(255, 255, 255, 1)";
    ctx.beginPath();
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    ctx.fill();
}
}

function processAudio(){

    var context = new (window.AudioContext || window.webkitAudioContext)();

    var cnt = 0;

    // https://www.siili.com/news/creating-voice-recognition-bot-web-app-amazon-aws-lex

    var recordRTC = null;
    navigator.getUserMedia({video: false, audio: true}, initializeRecorder, function(e){ console.log(e); });
    function initializeRecorder(stream) {
        var audioInput = context.createMediaStreamSource(stream);
        var bufferSize = 8192;
        // create a javascript node
        var recorder = context.createScriptProcessor(bufferSize, 1, 1);
        //var recorder = context.createJavaScriptNode(bufferSize, 1, 1);
        // specify the processing function
        recorder.onaudioprocess = recorderProcess;
        // connect stream to our recorder
        audioInput.connect(recorder);
        // connect our recorder to the previous destination
        recorder.connect(context.destination);
    }
    function recorderProcess(e) {
//        cnt++; if(cnt >= 50) return;

        audioBuffer = e.inputBuffer;
        resampleAndSend(audioBuffer);
    }

    function resampleAndSend(audiobuffer){
        inBuffer = audiobuffer.getChannelData(0);
//        inBuffer.fill(1);
//        console.log(inBuffer);
        recw.postMessage({type: 'pcm', data: inBuffer, sampleRate: audiobuffer.sampleRate});
console.log("duration: ", audiobuffer.duration, inBuffer.length, audiobuffer.length);
/*

        if(audiobuffer.sampleRate == serverSampleRate){
            recw.postMessage({type: 'pcm', data: inBuffer});
            return;
        }

        var o = new OfflineAudioContext(1, audiobuffer.length*serverSampleRate/audiobuffer.sampleRate, serverSampleRate);

        // create audio buffer
        var osrc = o.createBufferSource();
        osrc.buffer = audiobuffer;
        osrc.connect(o.destination);
        osrc.start(0);
        o.oncomplete = function (event){
            abuffer = event.renderedBuffer;
            typedbuffer = abuffer.getChannelData(0);
            console.log(typedbuffer.length*4);
            recw.postMessage({type: 'pcm', data: typedbuffer});
        }
        o.startRendering();
*/
    }
}

  </script>
</body>
</html>
